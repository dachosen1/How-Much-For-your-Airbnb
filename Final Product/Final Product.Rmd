---
title: "Kaggle Report"
author: "Anderson Nelson"
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r Summary , include=FALSE}
```

The dataset contains a listing of over 25,000 Airbnb rentals in New York City. The goal of this project is to predict the price for a rental using over 90 variables on the property, host, and past reviews, and to illustrate my thought process on model creation, and data exploration.
My hypothesis on the variables that impact customer service are supply, demand, locations, customers services, size in square footage, type of property, capacity, certain amenities. Reviewing the variables of the data reveals the variables that belong in that category. 

### Data Cleaning 


```{r Importing Libraries, include=FALSE}
library(tidyverse); library(leaps); library(caTools)
```

```{r Imprting Data, echo=TRUE}
dataset <- read.csv("analysisData.csv")
dataset <- select(id,host_id,zipcode,room_type,property_type,accommodates,host_since,host_response_time,bathrooms,bedrooms,beds,bed_type,price,neighbourhood_cleansed,neighbourhood_group_cleansed,availability_30,availability_60,availability_90,availability_365,number_of_reviews,is_business_travel_ready,cleaning_fee,host_is_superhost,review_scores_communication,reviews_per_month,review_scores_rating,review_scores_accuracy,review_scores_cleanliness,review_scores_checkin,review_scores_communication,review_scores_location,review_scores_value,calendar_updated,calculated_host_listings_count,require_guest_phone_verification,require_guest_profile_picture,cancellation_policy,instant_bookable,last_review,first_review,maximum_nights,minimum_nights,extra_people,guests_included,latitude,longitude,.data = dataset)
```

We now have an abridge version of this original dataset. The columns that were removed were one of the following of the following categories: duplicate, contributed to bias, nor relevant to the problem. Lets take a look at how many columns we have.
```{r Checking Dimension, echo=TRUE}
dim(dataset)
```

Do we have any NA in the documents? Less than 1% of the dataset has any NA, which is not significant, a deeper dive indicate that the variables are concentrated in Weekly_price, Monthly_price. 
```{r NA Sum, echo=TRUE}
(sum(is.na(dataset)) / (ncol(dataset) * nrow(dataset))) * 100
```

However in the scoring data zipcode also had a few missing data. I was able to combine both the zipcodes from both datasets, and removed all the duplicates. That allowed to me to see the neighborhoods clusters for each of the zipcode.Since there were only 93 misssing data, I joined the most recurring zipdode in to the scoring data by using the neighborhood grop. 
```{r Zip Code NA, echo=TRUE}
#zipcodena <- read.csv("zipcodena.csv")
#merge(x = zipcodena, y = na_zipcode)
#merger <- dataset%>%
# select(neighbourhood_cleansed, zipcode)%>%
# filter(is.na(zipcode))
#NEWZIP <- merge(x = zipcodena, y = merger)
#dataset$zipcode[is.na(dataset$zipcode)] <- NEWZIP$n

```

I also checked if there were any duplicated data, and the result indicate that there are none.
```{r NA check, echo=TRUE}
sum(duplicated(x = dataset))
```

The below illustrate the discritbuion of the price column, an interesing observation is the range, and that there are prices that are 0.  it is unlikely that the seller would list their property for free. There are instances where that could occur but that's most likely an outlier. 
```{r Price Distribution , echo=TRUE}
boxplot(dataset$price)
summary(dataset$price)
```
There are only 25 variables that are listed as 0, and it confirms my suspicion. It's best to remove them. 

```{r Addressing Null Prices, echo=TRUE}
length(dataset$price[dataset$price == 0])
dataset <- dataset[!dataset$price == 0,]

```
A quick look at property type reveals that there are 35 unique property type. At first glance, it doesn't make sense as to why there is that many. Lets take at look at the distribution of property accross the dataset. 
```{r Property Type , echo=TRUE}
length(unique(dataset$property_type))
```
Over 98% of the property types belong to one of 5 categories, It seems that there are some variables that have are outliers in the property type. 
```{r Property Type II, echo=TRUE}
dataset%>%
 select(property_type)%>%
 count(property_type,sort = TRUE)%>%
 mutate(percentage = (n / sum(n)*100))%>%
 filter(percentage > 1)
```
I've condense the remaining variables into one column called "other". 
```{r Property Type III, echo=TRUE}
dataset$property_type[!dataset$property_type == "Apartment" & !dataset$property_type =="House" &
                        !dataset$property_type =="Loft" & !dataset$property_type =="Condominium"
                      & !dataset$property_type =="Townhouse"] <- "Other"
dataset$property_type<- droplevels(dataset$property_type)
```


```{r Bathrooms, echo=TRUE}
histogram(dataset$bathrooms)
dataset%>%
 select(bathrooms)%>%
 group_by(bathrooms)%>%
 count(bathrooms)%>%
 ggplot(aes(x = bathrooms, y = n)) + geom_bar(stat = "identity") 

```


```{r Bedroom Visualization, echo=TRUE}
histogram(dataset$bedrooms)

dataset%>%
 select(bedrooms, price)%>%
 group_by(bedrooms)%>%
 ggplot(aes(x = bedrooms, y = price)) + geom_smooth() 

```

```{r Bedroom and Room Type, echo=TRUE}
dataset%>%
 filter(bedrooms == 0)%>%
 select(room_type)%>%
 count(room_type)

```

```{r Cleaning Fee, echo=TRUE}
dataset%>%
 select(cleaning_fee, price)%>%
 group_by(cleaning_fee)%>%
 ggplot(aes(x = cleaning_fee, y = price)) + geom_smooth() 

```

```{r Cleaning Fee NA, echo=TRUE}
summary(dataset$cleaning_fee)
dataset$cleaning_fee[is.na(dataset$cleaning_fee)] <- 0

```

```{r Beds, echo=TRUE}
dataset$beds[is.na(dataset$beds)] <- median(dataset$beds,na.rm = TRUE)
```



```{r New Column, echo=TRUE}
dataset$review_scores_sum <- dataset$review_scores_accuracy + dataset$review_scores_communication + 
 dataset$review_scores_rating + dataset$review_scores_checkin + dataset$review_scores_cleanliness + 
 dataset$review_scores_location + dataset$review_scores_value

```


```{r Review Score Sum and Price Grapth , echo=TRUE}
dataset%>%
 select(review_scores_sum, price)%>%
 group_by(review_scores_sum)%>%
 ggplot(aes(x = review_scores_sum, y = price)) + geom_smooth() 

```


```{r Creating New column, echo=TRUE}

```

#Models 
#Linear Regression
```{r Train and Test Set, echo=TRUE}
set.seed(100)
split <- sample.split(Y = dataset$price, SplitRatio = .8)
trainingset <- dataset[split,]
testset <- dataset[!split,]
```


```{r linear Regression Variables, echo=TRUE}
Model_LR <- lm(price ~ ., data = trainingset);
Pred_LR <- predict(Model_LR);
sqrt(mean((Pred_LR - trainingset$price)^2))

```


```{r out of sample test set, echo=TRUE}
Pred_LR_test <- predict(Model_LR, newdata = testset)
sqrt(mean((Pred_LR_test - testset$price)^2))
```


```{r linear Regression with 12 Variables, echo=TRUE}
Model_LR2 <- lm(price ~ bedrooms + accommodates + bedrooms + beds + cleaning_fee + host_since + extra_people + latitude + guests_included + review_scores_communication, data = trainingset);
Pred_LR2 <- predict(Model_LR2);
sqrt(mean((Pred_LR2 - trainingset$price)^2))

```


```{r out of sample test set, echo=TRUE}
Pred_LR_test2 <- predict(Model_LR2, newdata = testset)
sqrt(mean((Pred_LR_test2 - testset$price)^2))
```

#Descion Trees 

```{r Descicion Tree model, echo=TRUE}
library(rpart)
Model_DT <- rpart(price ~., data = trainingset, method = "class")
```


```{r Descicion Tree variable importance, echo=TRUE}
Model_DT$variable.importance
```


```{r Descicion Tree features, echo=TRUE}
Model_DT$control
```


```{r Descicion Tree training set RMSE, echo=TRUE}
pred_DT <- predict(Model_DT)
sqrt(mean((pred_DT - trainingset$price)^2))

```

```{r Descicion Test set RMSE, echo=TRUE}
pred_DT_test <- predict(Model_DT, newdata = testset)
sqrt(mean((pred_DT_test - testset$price)^2))
```


```{r Descicion Tree model part 2 , echo=TRUE}
tuneControl <- trainControl(method = "cv",number = 10)
tunegrid <- expand.grid(0,0.1,0.05)
```


```{r Descicion Tree model part 2 , echo=TRUE}
Model_DT2 <- rpart(price ~., data = trainingset, method = "class")
```


```{r Descicion Tree training set RMSE part 2 , echo=TRUE}
pred_DT <- predict(Model_DT)
sqrt(mean((pred_DT - trainingset$price)^2))

```

```{r Descicion Test set RMSE part 2 , echo=TRUE}
pred_DT_test <- predict(Model_DT, newdata = testset)
sqrt(mean((pred_DT_test - testset$price)^2))
```


#Random Forest 

```{r random forest , echo=TRUE}


```


